
**************************************
播放
水印
音乐
转场
滤镜
保存
旋转问题
保存走播放流程
硬解硬保速度优化
硬解硬编保存文件时长缩短，播放速度变快问题
stop muxer failed
不同采样率、通道数的音频怎么混音
混音方案
其他电脑 gl3stubInit() 找不到
assertion "thread" failed
软解硬保ijk实例提前释放
**************************************


**************************************
播放
**************************************
《使用ffmpeg合并视频文件的三种方法 》：http://blog.csdn.net/u012587637/article/details/51670975


**************************************
水印
**************************************
秀秀中预览视频时不需显示水印，需要能在最后保存时加入水印
问题：水印错误:
 E/IJKMEDIA: Failed to avformat_open_input '/storage/emulated/0/VideoEditorDir/test.jpg',ret=-1094995529
 E/IJKMEDIA: Error initializing filter 'movie'
 E/IJKMEDIA: *********************************Error initializing filter 'movie'
 E/IJKMEDIA:  with args '/storage/emulated/0/VideoEditorDir/test.jpg'
原因:https://stackoverflow.com/questions/10455611/how-to-solve-ffmpeg-watermark-no-such-filter-movie-and-failed-to-avformat
解决：ijk未开启对应的demuxers
问题：水印能否在ijk的硬解时添加失败，
     ret = av_buffersrc_add_frame(filt_in, frame);     返回 -22
     错误码 libavutil/error.c中   -22代表：无效参数
     av_buffersrc_add_frame  索引到：  av_frame_ref   ---》  av_frame_copy(dst, src)   ---》   frame_copy_video 方法中的：
         planes = av_pix_fmt_count_planes(dst->format);
            for (i = 0; i < planes; i++){
            if (!dst->data[i] || !src->data[i]){
                return AVERROR(EINVAL);
            }
         }
     原因： src->data[0] = 0
     软解帧此值不为0,硬解帧此值为0
     硬解帧异常，虽然可以加入帧缓冲队列显示，但是其format和data值都异常
     通过调用av_pix_fmt_count_planes方法得知 format=10001为无效format
     解决方案：首先搞懂软解和硬解出来的帧即avframe的区别
     软解: format=0对应于AV_PIX_FMT_YUV420P
     硬解: format=10001无对应格式(format一共347个)
解决：改用ffmpeg3.1后自带的mediacodec硬解后，由于其走的软解流程，添加成功
     问题：-enable-jni 报错
     -enable-jni 报错： ERROR: jni not found  Objective-C compiler not installed on this system
     高版本ffmpeg也会报错 ERROR: jni not found 但具体原因不一样
     解决：--target-os=linux ---》 --target-os=android
     成功实现硬解水印：https://www.cnblogs.com/elesos/p/6860865.html
加水印暂停后崩溃问题：暂时屏蔽destory方法

**************************************
音乐
**************************************
《SDL 与 FFMPEG 音乐播放器开发（2）——混播多个音频》：http://blog.csdn.net/u013080313/article/details/50387244
《ffmpeg实战教程（十二）为视频添加/更换背景音乐 》：http://blog.csdn.net/king1425/article/details/72628607
工作：1.播放  2.保存写入
无声问题：音频未开始解码
原因：configure_audio_filters 出错
暂时 #define CONFIG_AVFILTER 0 屏蔽configure_audio_filters操作
解决：--enable-filter=aresample
1.播放
>音频滤镜实现
>播放实现
  如何在原播放器基础上多重叠播放一个音频

**************************************
转场
**************************************

**************************************
滤镜
**************************************
问题：测试发现同等输出设置下，


**************************************
保存
**************************************
Add Android encoders support to MediaCodec implementation：https://trac.ffmpeg.org/ticket/6407
关于metadata信息：（播放时需要什么就获取什么，设置什么）
1.获取视频的metadata并记录
2.保存时将metadata信息设置生效
自己编码保存的视频，手机系统播放器无法播放，ijkplayer却可以播放
考虑应该是手机系统播放器依赖metadata信息，ijk不依赖，而我没设置全metadata信息
问题：系统播放器无法播放，ijk可以播放，不知需要设置哪些metadata信息
解决：视频编码器设置 enc_ctx->flags = AV_CODEC_FLAG_GLOBAL_HEADER （不是metadata的问题！！！！！）
concat问题:
问题:ijk播放正常，但是系统播放器会跳过第一段视频,duration有问题
解决：ffconcat文件写入的duration错误， ms没有转换为s
硬保：
mtmvcore 硬保需4.3及以上，4.1 引入 MediaExtractor， 4.3 引入 MediaMuxer类
可以完全使用android api,但视频格式兼容性不足，NO
问题：
保存时若单用硬解，会在muxing时即 av_interleaved_write_frame 返回-22（无效参数）
分析：有些帧有问题？
暂时解决：忽略av_interleaved_write_frame返回值，输出文件大小由软解的 0.91M---->796kb

谈谈关于Android视频编码的那些坑:https://ragnraok.github.io/android_video_record.html

ffmpeg 编码后得到的是 AVPacket , 然后写入 AVFormatContext 进行 mux
http://blog.csdn.net/leixiaohua1020/article/details/14215755
mediacodec 编码后得到的是 ByteBuffer ,可通过 MediaMuxer 进行 mux
https://bigflake.com/mediacodec/CameraToMpegTest.java.txt

ffmpeg 若要集成硬编，使用 mediacodec 将 frame 编码为 ByteBuffer 后，转为 AVPacket 然后去 mux 。

AVFrame  -->  YUV  -->  ByteBuffer  -->  硬码  -->  ByteBuffer  -->  AVPacket

********************
********************    用 mediacodec 编码后 就用 mediamuxer 封装！！！
                             视频和音频都传到java层
********************         不用转成 AVPacket 用 ffmpeg 封装 ！！！
********************

应该采用4.1的api：
4.1 : getInputBuffers()  getOutputBuffers()
5.0 : getInputBuffer()   getOutputBuffer()

mtmvcore ios启用硬解，android未使用硬解
若用硬解+硬编（速度超快）
需要解决的问题：
1.音频混合 （若用户未添加背景音乐，则无需编解码音频）
2.安卓版本兼容性（若低于4.3，改用软解软编）
3.视频格式兼容性（若不兼容，改用软解硬编，若硬编也不支持，改用软编）


opengl：

对于预览：
开启gl渲染：mIjkMediaPlayer.setOption(IjkMediaPlayer.OPT_CATEGORY_PLAYER, "overlay-format", "fcc-_es2");
问题：右侧有绿边
分析：https://github.com/Bilibili/ijkplayer/issues/854

对于保存：


**************************************
旋转问题
**************************************
安卓手机录制的视频，往往会带rotation信息，且宽高会随旋转角度变化
比如720x1280的小米手机录制的视频实际宽高是1280x720(通过解码器获取), rotation=90度
手机系统播放器和ijk能按720x1280的宽高去播放视频，这是因为根据rotation对frame进行了旋转
ijk可以看到刚开始播放的一瞬间是1280x720的比例，这是因为ijk第一次是通过解码器获取的宽高，之后才由旋转后的frame宽高生效
问题：怎么解决ijk刚开始播放的一瞬间是1280x720的比例?
解决：不能直接把解码器获取的宽高穿给上层，要结合rotation信息
关于显示：
对于宽>高的视频必须做旋转
底层同学的建议：view层级旋转比较好，解码后旋转有坑
但ffplay就是解码后旋转的，解码后通过avfilter对frame进行了旋转
ijk软解跟ffplay一样是通过avfilter对frame做了旋转
ijk硬解对于有角度的视频默认不进行旋转，需要设置：
mIjkMediaPlayer.setOption(IjkMediaPlayer.OPT_CATEGORY_PLAYER, "mediacodec-auto-rotate", 1);
对应与底层的：ffpipenode_android_mediacodec_vdec.c  :  "mediacodec_auto_rotate"处的处理
如果安卓版本大于等于21，直接对硬解码器设置解码出的帧的旋转角度
如果小于21，发送MEDIA_INFO_VIDEO_ROTATION_CHANGED信息通知上层mRenderView旋转角度（只有TextureRenderView支持旋转）
surfaceview不支持旋转，如果srufaceview比TextureRenderView性能好的话，可以做下兼容，小于21的用TextureRenderView
关于保存：
问题：怎么保存正常的宽高和rotation，使其可以正常播放?
1.像原视频一样宽高相反且保留rotation信息（无需旋转帧），av_dict_set(&m_pDstVideoStream->metadata,"rotate","90",0);
2.宽高正常且rotation置0（需要旋转帧，将ffplay的旋转逻辑搬到保存流程）

解决方案：
软编：av_dict_set(&m_pDstVideoStream->metadata,"rotate","90",0)
硬编：MediaMuxer.setOrientationHint(90)

**************************************
保存走播放流程
**************************************
保存和预览区别：预览有时间控制，要渲染到view; 保存渲染后要编码到本地
相同的流程：解封装、读包、解码、渲染
对相同的流程进行抽象封装，减少维护成本
mtmvcore便是这样实现的，播放和保存用同一播放器实例操作
理想情况是：保存和播放走同一套流程，但保存并不依赖播放器实例
>首先实现用同一播放器实例实现保存：

渲染后的rgb数据转为yuv然后通过 av_image_fill_arrays 函数塞入原 AVFrame 接着进行软编


**************************************
硬解硬保速度优化
**************************************
仿照底层方案，设置多个线程同步进行：
读包线程、视频解码线程、音频解码线程、渲染线程、视频编码线程、音频编码线程、写包线程
如果加背景音乐，再添加：背景音乐读包线程、背景音乐解码线程

结合java层api情况，  比较耗时的操作： 渲染、 取出（包含编码）

视频帧在surface中解码、渲染、编码，当解码后我们才可以介入，紧接着必须串行调用渲染操作，取出操作

音频帧可以介入的是解码出pcm后，设置一个编码线程

1. 读包线程： 循环读视频的视频包和音频包：  dequeueInputBuffer readSampleData  queueInputBuffer

2. 视频渲染、编码、取出、写入线程： drawImage、dequeueOutputBuffer  writeSampleData，然后 swapBuffers

3. 音频处理线程(音量调节)： dequeueOutputBuffer 轮询取出 pcm ，进行处理， 加入pcm缓冲队列

4. 音频编码线程： 轮询从pcm缓冲队列取出pcm ， queueInputBuffer 送去 编码，编码后 writeSampleData


如果要混音：

1.读包线程中同步读背景音乐

2.背景音乐处理线程：dequeueOutputBuffer 轮询取出 pcm  ，同步控制，和同一时间戳 原音 混音，




音频处理可以设置两个缓冲队列，分别为处理前和处理后




**************************************
硬解硬编保存文件时长缩短，播放速度变快问题
**************************************
之前是：
mCodecOutputSurface.setPresentationTime(computePresentationTimeNsec(decodeCount));
  private static long computePresentationTimeNsec(int frameIndex) {
        return frameIndex * 1000000000L / 30;
    }

解决：
mCodecOutputSurface.setPresentationTime(bufferInfo.presentationTimeUs*1000);



**************************************
同步写入视频/音频数据，音频数据丢失
**************************************
现象：先写完所有视频帧，再写音频帧，正常； 同步开始写视频帧和音频帧，音频会丢失
解决：应该先写完一帧视频帧后，才可以开始写音频帧


**************************************
stop muxer failed
**************************************
原因1:写入音频数据时最后将presentationTimeUs=0的结束帧写进去了
原因2：没有先写视频帧再写音频帧



**************************************
不同采样率、通道数的音频怎么混音
**************************************
先转换成相同的，再进行混音：
http://www.open-open.com/lib/view/open1467185744307.html


**************************************
混音方案
**************************************
步骤：转换、对齐、混音

硬件解码编码时如何将音频流和背景音乐混音
查阅资料得知相同采样率、相同采样点字节数、相同通道的音频才能做混音
先控制三者相同，都进行硬解，音频流和背景音乐解码出来的音频帧数据大小不一样(背景音乐比音频流byte数组长度长)
混音算法要求一帧数据长度相同，把音频帧数据补位则音频模糊，把背景音乐多出来的数据丢弃则背景音乐模糊

分析：通道数、采样点字节数可以用java代码解决
方案：设置一个数据长度对齐线程，使背景音乐数据长度与音频流一致








**************************************
其他电脑 gl3stubInit() 找不到
**************************************
其他电脑编译，提示 gl3stubInit() 方法找不到
本来未配置 "-DANDROID_PLATFORM=android-15" 的话，cmake中获取到的应该是minsdkversion
但是其他电脑获取的不是min，而是大于18的版本，导致找不到
解决：设置"-DANDROID_PLATFORM=android-15"
又出现问题：无法编译通过
解决方案：ndk版本更新到 16.1.4479499

**************************************
assertion "thread" failed
**************************************
更新as版本后运行，程序运行到 assert() 方法时 崩溃：
void SDL_WaitThread(SDL_Thread *, int *): assertion "thread" failed
尝试解决：Go to: File > Invalidate Caches/Restart and select Invalidate and Restart
参考：https://stackoverflow.com/questions/20063532/assertion-error-in-android-studio-when-trying-to-compile-the-working-project
问题：仍然存在 assertion "thread" failed ！
解决：cFlags 添加 DNDEBUG ， assert函数 需要此标记才能使用


**************************************
软解硬保ijk实例提前释放
**************************************
正在读取gpu渲染的帧时， java层调用了 IjkMediaPlayer_native_finalize 导致ijk释放，从而中断
分析：找到什么动作触发了native_finalize方法
原因: HardMuxTask 运行完后释放了ijkplayer引用，由gc回收
解决：HardMuxTask调用底层保存后线程进入等待，待底层保存完后再解锁



























