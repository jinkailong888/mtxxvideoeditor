
**************************************
播放
水印
音乐
转场
滤镜
保存
旋转问题
保存走播放流程
硬解硬保速度优化
硬解硬编保存文件时长缩短，播放速度变快问题
stop muxer failed
不同采样率、通道数的音频怎么混音
混音方案
其他电脑 gl3stubInit() 找不到
assertion "thread" failed
软解硬保ijk实例提前释放
软解硬保视频帧格式问题
视频模糊马赛克问题
软解软保视频编码
软解软保音频编码
ffeditor例子屏蔽avfilter后音频杂音问题
软解软保gl渲染帧模式
软解硬保音频编码错误
argb->yuv 色差问题
**************************************


**************************************
播放
**************************************
《使用ffmpeg合并视频文件的三种方法 》：http://blog.csdn.net/u012587637/article/details/51670975


**************************************
水印
**************************************
秀秀中预览视频时不需显示水印，需要能在最后保存时加入水印
问题：水印错误:
 E/IJKMEDIA: Failed to avformat_open_input '/storage/emulated/0/VideoEditorDir/test.jpg',ret=-1094995529
 E/IJKMEDIA: Error initializing filter 'movie'
 E/IJKMEDIA: *********************************Error initializing filter 'movie'
 E/IJKMEDIA:  with args '/storage/emulated/0/VideoEditorDir/test.jpg'
原因:https://stackoverflow.com/questions/10455611/how-to-solve-ffmpeg-watermark-no-such-filter-movie-and-failed-to-avformat
解决：ijk未开启对应的demuxers
问题：水印能否在ijk的硬解时添加失败，
     ret = av_buffersrc_add_frame(filt_in, frame);     返回 -22
     错误码 libavutil/error.c中   -22代表：无效参数
     av_buffersrc_add_frame  索引到：  av_frame_ref   ---》  av_frame_copy(dst, src)   ---》   frame_copy_video 方法中的：
         planes = av_pix_fmt_count_planes(dst->format);
            for (i = 0; i < planes; i++){
            if (!dst->data[i] || !src->data[i]){
                return AVERROR(EINVAL);
            }
         }
     原因： src->data[0] = 0
     软解帧此值不为0,硬解帧此值为0
     硬解帧异常，虽然可以加入帧缓冲队列显示，但是其format和data值都异常
     通过调用av_pix_fmt_count_planes方法得知 format=10001为无效format
     解决方案：首先搞懂软解和硬解出来的帧即avframe的区别
     软解: format=0对应于AV_PIX_FMT_YUV420P
     硬解: format=10001无对应格式(format一共347个)
解决：改用ffmpeg3.1后自带的mediacodec硬解后，由于其走的软解流程，添加成功
     问题：-enable-jni 报错
     -enable-jni 报错： ERROR: jni not found  Objective-C compiler not installed on this system
     高版本ffmpeg也会报错 ERROR: jni not found 但具体原因不一样
     解决：--target-os=linux ---》 --target-os=android
     成功实现硬解水印：https://www.cnblogs.com/elesos/p/6860865.html
加水印暂停后崩溃问题：暂时屏蔽destory方法

**************************************
音乐
**************************************
《SDL 与 FFMPEG 音乐播放器开发（2）——混播多个音频》：http://blog.csdn.net/u013080313/article/details/50387244
《ffmpeg实战教程（十二）为视频添加/更换背景音乐 》：http://blog.csdn.net/king1425/article/details/72628607
工作：1.播放  2.保存写入
无声问题：音频未开始解码
原因：configure_audio_filters 出错
暂时 #define CONFIG_AVFILTER 0 屏蔽configure_audio_filters操作
解决：--enable-filter=aresample
1.播放
>音频滤镜实现
>播放实现
  如何在原播放器基础上多重叠播放一个音频

**************************************
转场
**************************************

**************************************
滤镜
**************************************
问题：测试发现同等输出设置下，


**************************************
保存
**************************************
Add Android encoders support to MediaCodec implementation：https://trac.ffmpeg.org/ticket/6407
关于metadata信息：（播放时需要什么就获取什么，设置什么）
1.获取视频的metadata并记录
2.保存时将metadata信息设置生效
自己编码保存的视频，手机系统播放器无法播放，ijkplayer却可以播放
考虑应该是手机系统播放器依赖metadata信息，ijk不依赖，而我没设置全metadata信息
问题：系统播放器无法播放，ijk可以播放，不知需要设置哪些metadata信息
解决：视频编码器设置 enc_ctx->flags = AV_CODEC_FLAG_GLOBAL_HEADER （不是metadata的问题！！！！！）
concat问题:
问题:ijk播放正常，但是系统播放器会跳过第一段视频,duration有问题
解决：ffconcat文件写入的duration错误， ms没有转换为s
硬保：
mtmvcore 硬保需4.3及以上，4.1 引入 MediaExtractor， 4.3 引入 MediaMuxer类
可以完全使用android api,但视频格式兼容性不足，NO
问题：
保存时若单用硬解，会在muxing时即 av_interleaved_write_frame 返回-22（无效参数）
分析：有些帧有问题？
暂时解决：忽略av_interleaved_write_frame返回值，输出文件大小由软解的 0.91M---->796kb

谈谈关于Android视频编码的那些坑:https://ragnraok.github.io/android_video_record.html

ffmpeg 编码后得到的是 AVPacket , 然后写入 AVFormatContext 进行 mux
http://blog.csdn.net/leixiaohua1020/article/details/14215755
mediacodec 编码后得到的是 ByteBuffer ,可通过 MediaMuxer 进行 mux
https://bigflake.com/mediacodec/CameraToMpegTest.java.txt

ffmpeg 若要集成硬编，使用 mediacodec 将 frame 编码为 ByteBuffer 后，转为 AVPacket 然后去 mux 。

AVFrame  -->  YUV  -->  ByteBuffer  -->  硬码  -->  ByteBuffer  -->  AVPacket

********************
********************    用 mediacodec 编码后 就用 mediamuxer 封装！！！
                             视频和音频都传到java层
********************         不用转成 AVPacket 用 ffmpeg 封装 ！！！
********************

应该采用4.1的api：
4.1 : getInputBuffers()  getOutputBuffers()
5.0 : getInputBuffer()   getOutputBuffer()

mtmvcore ios启用硬解，android未使用硬解
若用硬解+硬编（速度超快）
需要解决的问题：
1.音频混合 （若用户未添加背景音乐，则无需编解码音频）
2.安卓版本兼容性（若低于4.3，改用软解软编）
3.视频格式兼容性（若不兼容，改用软解硬编，若硬编也不支持，改用软编）


opengl：

对于预览：
开启gl渲染：mIjkMediaPlayer.setOption(IjkMediaPlayer.OPT_CATEGORY_PLAYER, "overlay-format", "fcc-_es2");
问题：右侧有绿边
分析：https://github.com/Bilibili/ijkplayer/issues/854

对于保存：


**************************************
旋转问题
**************************************
安卓手机录制的视频，往往会带rotation信息，且宽高会随旋转角度变化
比如720x1280的小米手机录制的视频实际宽高是1280x720(通过解码器获取), rotation=90度
手机系统播放器和ijk能按720x1280的宽高去播放视频，这是因为根据rotation对frame进行了旋转
ijk可以看到刚开始播放的一瞬间是1280x720的比例，这是因为ijk第一次是通过解码器获取的宽高，之后才由旋转后的frame宽高生效
问题：怎么解决ijk刚开始播放的一瞬间是1280x720的比例?
解决：不能直接把解码器获取的宽高穿给上层，要结合rotation信息
关于显示：
对于宽>高的视频必须做旋转
底层同学的建议：view层级旋转比较好，解码后旋转有坑
但ffplay就是解码后旋转的，解码后通过avfilter对frame进行了旋转
ijk软解跟ffplay一样是通过avfilter对frame做了旋转
ijk硬解对于有角度的视频默认不进行旋转，需要设置：
mIjkMediaPlayer.setOption(IjkMediaPlayer.OPT_CATEGORY_PLAYER, "mediacodec-auto-rotate", 1);
对应与底层的：ffpipenode_android_mediacodec_vdec.c  :  "mediacodec_auto_rotate"处的处理
如果安卓版本大于等于21，直接对硬解码器设置解码出的帧的旋转角度
如果小于21，发送MEDIA_INFO_VIDEO_ROTATION_CHANGED信息通知上层mRenderView旋转角度（只有TextureRenderView支持旋转）
surfaceview不支持旋转，如果srufaceview比TextureRenderView性能好的话，可以做下兼容，小于21的用TextureRenderView
关于保存：
问题：怎么保存正常的宽高和rotation，使其可以正常播放?
1.像原视频一样宽高相反且保留rotation信息（无需旋转帧），av_dict_set(&m_pDstVideoStream->metadata,"rotate","90",0);
2.宽高正常且rotation置0（需要旋转帧，将ffplay的旋转逻辑搬到保存流程）

解决方案：
软编：av_dict_set(&m_pDstVideoStream->metadata,"rotate","90",0)
硬编：MediaMuxer.setOrientationHint(90)

**************************************
保存走播放流程
**************************************
保存和预览区别：预览有时间控制，要渲染到view; 保存渲染后要编码到本地
相同的流程：解封装、读包、解码、渲染
对相同的流程进行抽象封装，减少维护成本
mtmvcore便是这样实现的，播放和保存用同一播放器实例操作
理想情况是：保存和播放走同一套流程，但保存并不依赖播放器实例
>首先实现用同一播放器实例实现保存：

渲染后的rgb数据转为yuv然后通过 av_image_fill_arrays 函数塞入原 AVFrame 接着进行软编


**************************************
硬解硬保速度优化
**************************************
仿照底层方案，设置多个线程同步进行：
读包线程、视频解码线程、音频解码线程、渲染线程、视频编码线程、音频编码线程、写包线程
如果加背景音乐，再添加：背景音乐读包线程、背景音乐解码线程

结合java层api情况，  比较耗时的操作： 渲染、 取出（包含编码）

视频帧在surface中解码、渲染、编码，当解码后我们才可以介入，紧接着必须串行调用渲染操作，取出操作

音频帧可以介入的是解码出pcm后，设置一个编码线程

1. 读包线程： 循环读视频的视频包和音频包：  dequeueInputBuffer readSampleData  queueInputBuffer

2. 视频渲染、编码、取出、写入线程： drawImage、dequeueOutputBuffer  writeSampleData，然后 swapBuffers

3. 音频处理线程(音量调节)： dequeueOutputBuffer 轮询取出 pcm ，进行处理， 加入pcm缓冲队列

4. 音频编码线程： 轮询从pcm缓冲队列取出pcm ， queueInputBuffer 送去 编码，编码后 writeSampleData


如果要混音：

1.读包线程中同步读背景音乐

2.背景音乐处理线程：dequeueOutputBuffer 轮询取出 pcm  ，同步控制，和同一时间戳 原音 混音，




音频处理可以设置两个缓冲队列，分别为处理前和处理后




**************************************
硬解硬编保存文件时长缩短，播放速度变快问题
**************************************
之前是：
mCodecOutputSurface.setPresentationTime(computePresentationTimeNsec(decodeCount));
  private static long computePresentationTimeNsec(int frameIndex) {
        return frameIndex * 1000000000L / 30;
    }

解决：
mCodecOutputSurface.setPresentationTime(bufferInfo.presentationTimeUs*1000);



**************************************
同步写入视频/音频数据，音频数据丢失
**************************************
现象：先写完所有视频帧，再写音频帧，正常； 同步开始写视频帧和音频帧，音频会丢失
解决：应该先写完一帧视频帧后，才可以开始写音频帧


**************************************
stop muxer failed
**************************************
原因1:写入音频数据时最后将presentationTimeUs=0的结束帧写进去了
原因2：没有先写视频帧再写音频帧



**************************************
不同采样率、通道数的音频怎么混音
**************************************
先转换成相同的，再进行混音：
http://www.open-open.com/lib/view/open1467185744307.html

//todo avfilter对音频做重采样 ！


**************************************
混音方案
**************************************
步骤：转换、对齐、混音

硬件解码编码时如何将音频流和背景音乐混音
查阅资料得知相同采样率、相同采样点字节数、相同通道的音频才能做混音
先控制三者相同，都进行硬解，音频流和背景音乐解码出来的音频帧数据大小不一样(背景音乐比音频流byte数组长度长)
混音算法要求一帧数据长度相同，把音频帧数据补位则音频模糊，把背景音乐多出来的数据丢弃则背景音乐模糊

分析：通道数、采样点字节数可以用java代码解决
方案：设置一个数据长度对齐线程，使背景音乐数据长度与音频流一致








**************************************
其他电脑 gl3stubInit() 找不到
**************************************
其他电脑编译，提示 gl3stubInit() 方法找不到
本来未配置 "-DANDROID_PLATFORM=android-15" 的话，cmake中获取到的应该是minsdkversion
但是其他电脑获取的不是min，而是大于18的版本，导致找不到
解决：设置"-DANDROID_PLATFORM=android-15"
又出现问题：无法编译通过
解决方案：ndk版本更新到 16.1.4479499

**************************************
assertion "thread" failed
**************************************
更新as版本后运行，程序运行到 assert() 方法时 崩溃：
void SDL_WaitThread(SDL_Thread *, int *): assertion "thread" failed
尝试解决：Go to: File > Invalidate Caches/Restart and select Invalidate and Restart
参考：https://stackoverflow.com/questions/20063532/assertion-error-in-android-studio-when-trying-to-compile-the-working-project
问题：仍然存在 assertion "thread" failed ！
解决：cFlags 添加 DNDEBUG ， assert函数 需要此标记才能使用


**************************************
软解硬保ijk实例提前释放
**************************************
正在读取gpu渲染的帧时， java层调用了 IjkMediaPlayer_native_finalize 导致ijk释放，从而中断
分析：找到什么动作触发了native_finalize方法
原因: HardMuxTask 运行完后释放了ijkplayer引用，由gc回收
解决：HardMuxTask调用底层保存后线程进入等待，待底层保存完后再解锁


**************************************
软解硬保视频帧格式问题
**************************************
gl中取出的是 RGBA  ， mediacodec 支持的编码帧格式为？
需要转换成 mediacodec 支持的帧格式， 再编码封装
微信Android视频编码爬过的那些坑.md：
https://github.com/WeMobileDev/article/blob/master/%E5%BE%AE%E4%BF%A1Android%E8%A7%86%E9%A2%91%E7%BC%96%E7%A0%81%E7%88%AC%E8%BF%87%E7%9A%84%E9%82%A3%E4%BA%9B%E5%9D%91.md


**************************************
视频模糊马赛克问题
**************************************
红米上测试，屏蔽音频则视频清晰，若加上音频则会出现马赛克
原因: 音频采用copytrack方式，短时间大量音频写入时段 视频会出现方块模糊
解决：默认采用 decode encode 方式

**************************************
软解软保视频编码
**************************************
现象： avcodec_encode_video2 Error ret = -542398533
3
.
分析： 查看此方法源码：  x264/encoder.c/x264_encoder_encode方法 ，  此方法太繁琐
分析： 使用 error.h 宏定义的 av_err2str 方法 输出错误日志 ！！！

问题： non-strictly-monotonic PTS
解决： https://stackoverflow.com/questions/6603979/ffmpegavcodec-encode-video-setting-pts-h264

问题： 写入数据极小
现象:
  示例代码为： frame= 183 QP=35.00 NAL=2 Slice:P Poc:366 I:1004 P:975  SKIP:1621 size=15369 bytes

  此处为：     frame= 140 QP=0.00 NAL=2 Slice:P Poc:280 I:0    P:0    SKIP:3600 size=12 bytes

解决： 在video_refresh_thread方法中传入的AVFrame 数据已经转移到 Frame->mp了 ，传入时机调整到 queue_picture

问题： 调整到 queue_picture 后， 数据量极大

问题：

  Timestamps are unset in a packet for stream 0.
  This is deprecated and will stop working in the future.
  Fix your code to set the timestamps properly
  Encoder did not produce proper pts, making some up

理清思路：

  ffeditor: 读包 -> 解码 -> 编码 -> 封装
 ijkplayer:   播放器解码 -> 编码 -> 封装

 为什么ijkplayer无法实现？ 两个方案的不同点？

 1. 何时从播放器取解码后的帧， 检测取出的帧是否正常，与 ffeditor 对比 AVFrame 数据

 ffeditor:
     frame->width=1280
     frame->height=720
     frame->format=0
     frame->pts=26
     frame->pkt_dts=26
     frame->pkt_size=84052
     frame->linesize[0]=1280
     frame->linesize[1]=640
     frame->linesize[2]=640
     <encode>
     enc_pkt->size=1620
     enc_pkt->pts=12
     enc_pkt->dts=12
     enc_pkt->duration=0
     <rescale_ts>
     enc_pkt->size=1620
     enc_pkt->pts=3072
     enc_pkt->dts=3072
     enc_pkt->duration=0

 ijkplayer:
     frame->width=1280
     frame->height=720
     frame->format=0
     frame->pts=72565
     frame->pkt_dts=72565
     frame->pkt_size=63837
     frame->linesize[0]=1280
     frame->linesize[1]=640
     frame->linesize[2]=640
     <encode>
     enc_pkt->size=323150
     enc_pkt->pts=47181
     enc_pkt->dts=47181
     enc_pkt->duration=0

 可以看出 pts、dts 异常， ijkplayer 方式编码后包大小竟然变大 ？

  ijkplayer 播放解码完后pts就为此值：
     ffplay_decode frame->width=1280
     ffplay_decode frame->height=720
     ffplay_decode frame->format=0
     ffplay_decode frame->pts=513190
     ffplay_decode frame->pkt_dts=513190
     ffplay_decode frame->pkt_size=118768
     ffplay_decode frame->linesize[0]=1280
     ffplay_decode frame->linesize[1]=640
     ffplay_decode frame->linesize[2]=640

   ffeditor 解码后到编码也为此值，中间没有处理！
   所以应该是解码前的配置，ffeditor中在解码前调用了：

     av_packet_rescale_ts(&packet,
                  ifmt_ctx->streams[stream_index]->time_base,
                  stream_ctx[stream_index].dec_ctx->time_base);

   尝试屏蔽此方法，出现跟 ijkplayer 一样的 问题 ： 体积异常、时长异常！

   所以，应该在ijkplayer 中解码前加入此方法！

问题：加入后 文件大小和时长极小，可以播放，画质很糊

ffeditor video pts 变化：

start)))))))))
刚读出来包： 65268
输入流->解码器时间基转换后包：36      (输入流 num/den ：1/90000 , 解码器 num/den ：2/99)
刚解码后的帧：36
即将编码的帧：36
编码后得到的包：22
编码器->输出流时间基转换后包：5632    (输出流 num/den ：1/12672 , 编码器 num/den ：2/99)
end)))))))))))

问题: ffeditor  对手机录制的视频转码保存成功，对保存过的视频再次保存就会出现问题
现象：第一次保存后0.9M，时长正常为3S，再次保存后只有20K，时长小于1s
分析：可能就是第一次保存时pts没写对？ 先不管这个错误，先实现 ijkplayer 的第一次成功保存

ijkplayer video pts 变化：
start)))))))))
刚读出来的包：32598
即将解码的包：32598
解码后的帧：32598
end)))))))))))

可见未做转换，开始改造：

1.输入流->解码器时间基转换
问题：发现解码器时间基为 0/2，未设置
原因：对比ffeditor, avcodec_open2之前若设置 dec_ctx->framerate 打开后就会有时间基信息
      ffeditor中：  dec_ctx->framerate = av_guess_frame_rate(ifmt_ctx, stream, NULL);
      framerate=99， 打开解码器后时间基为 2/99
解决：修改ijkplayer，在打开编码器之前设置帧率


2.编码器->输出流时间基转换





**************************************
软解软保音频编码
**************************************

依然是模仿 editor 逻辑

ffeditor audio pts:

start)))))))))
刚读出来包： 164939
输入流->解码器时间基转换后包：164939   (输入流 num/den ：1/48000 , 解码器 num/den ：1/48000)
刚解码后的帧：164939
即将编码的帧：164939
编码后得到的包：162891
编码器->输出流时间基转换后包：162891   (输出流 num/den ：1/48000 , 编码器 num/den ：1/48000)
end)))))))))))

ffsoft audio pts
刚读出来的包: 正常
decoder_decode_frame 中 av_packet_rescale_ts前 : 0
分析: 加入到队列中的pts是正常的,播放器肯定做了一些工作改变了pts,首先应该检测到在哪里从音频包队列中取出音频包
解决: 调整播放器中取音频帧去编码的时机



**************************************
ffeditor例子屏蔽avfilter后音频杂音问题
**************************************

问题：如题
现象：开启avfilter后音频正常，关闭avfilter后音频出现杂音
分析：开启avfilter后对音频做了哪些工作？？？

音频帧：
  刚解码完 frame->width=0
  刚解码完 frame->height=0
  刚解码完 frame->format=8
  刚解码完 frame->pts=497664
  刚解码完 frame->pkt_dts=497664
  刚解码完 frame->pkt_size=185
  刚解码完 frame->linesize[0]=8192
  刚解码完 frame->linesize[1]=0
  刚解码完 frame->linesize[2]=0

filter_encode_write_frame 用 anull 渲染后：
  avfilter 渲染后的帧 frame->width=0
  avfilter 渲染后的帧 frame->height=0
  avfilter 渲染后的帧 frame->format=8
  avfilter 渲染后的帧 frame->pts=497664
  avfilter 渲染后的帧 frame->pkt_dts=497664
  avfilter 渲染后的帧 frame->pkt_size=185
  avfilter 渲染后的帧 frame->linesize[0]=8192
  avfilter 渲染后的帧 frame->linesize[1]=0
  avfilter 渲染后的帧 frame->linesize[2]=0

avfilter 除了渲染外中还多一句 ：filt_frame->pict_type = AV_PICTURE_TYPE_NONE

加上这一句仍然杂音.

avfilter 对音频的 sample_fmts 、channel_layouts 、sample_rates 做了转换， 此处杂音是因为 sample_fmts

要对音频重采样，用avfilter 很方便


**************************************
软解软保gl渲染帧模式
**************************************
软解软保gl视频帧->yuv->avframe
问题：数据量为12b，
原因：gl_util.c中读取大小应该为 w*h*4 而不是 w*h*2/3






**************************************
软解硬保音频编码错误
**************************************
底层传过来数据如下：正常
 encode: data.length=8192 pts=0
 encode: data.length=8192 pts=21333
 encode: data.length=8192 pts=42666
 encode: data.length=8192 pts=64000
 encode: data.length=8192 pts=85333
 encode: data.length=8192 pts=106666
 encode: data.length=8192 pts=128000
 encode: data.length=8192 pts=149333
 encode: data.length=8192 pts=170666
 encode: data.length=8192 pts=192000
 encode: data.length=8192 pts=213333
 encode: data.length=8192 pts=234666
 encode: data.length=8192 pts=256000

按次序加入编码队列，编码后竟然得到:

 写入音频数据bufferInfo: size=429 presentationTimeUs=23219 flags=0 offset=0
 写入音频数据bufferInfo: size=378 presentationTimeUs=21333 flags=0 offset=0

 写入音频数据bufferInfo: size=367 presentationTimeUs=44552 flags=0 offset=0
 写入音频数据bufferInfo: size=370 presentationTimeUs=42666 flags=0 offset=0

 写入音频数据bufferInfo: size=319 presentationTimeUs=65885 flags=0 offset=0
 写入音频数据bufferInfo: size=332 presentationTimeUs=64000 flags=0 offset=0

pts不递增，mux崩溃，为什么会这样？

先屏蔽掉pts变小的，声音异常。

分析：



**************************************
argb->yuv 色差问题
**************************************

ibyuv表示的排列顺序和Bitmap的RGBA表示的顺序是反向的。所以实际要调用libyuv::ABGRToI420才能得到正确的结果
https://www.tuicool.com/articles/ma2EVrJ
























